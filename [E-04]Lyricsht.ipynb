{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b0ec226",
   "metadata": {},
   "source": [
    "# 4. 작사가 인공지능 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e427ae31",
   "metadata": {},
   "source": [
    "## Step 1. 데이터 다운로드"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf40861",
   "metadata": {},
   "source": [
    "이미 실습(1) 데이터 다듬기에서 Cloud shell에 심볼릭 링크 ~/aiffel/lyricist/data를 생성하셨다면, ~/aiffel/lyricist/data/lyrics에 데이터가 있음.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f9b356",
   "metadata": {},
   "source": [
    "## Step 2. 데이터 읽어오기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94c85f5",
   "metadata": {},
   "source": [
    "glob 모듈을 사용하면 파일을 읽어오는 작업을 하기가 아주 용이함.\n",
    "glob 를 활용하여 모든 txt 파일을 읽어온 후, raw_corpus 리스트에 문장 단위로 저장."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb7decae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 크기: 187088\n",
      "Examples:\n",
      " [\"Now I've heard there was a secret chord\", 'That David played, and it pleased the Lord', \"But you don't really care for music, do you?\"]\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "txt_file_path = os.getenv('HOME')+'/aiffel/lyricist/data/lyrics/*'\n",
    "\n",
    "txt_list = glob.glob(txt_file_path)\n",
    "\n",
    "raw_corpus = []\n",
    "\n",
    "# 여러개의 txt 파일을 모두 읽어서 raw_corpus 에 담습니다.\n",
    "for txt_file in txt_list:\n",
    "    with open(txt_file, \"r\") as f:\n",
    "        raw = f.read().splitlines()\n",
    "        raw_corpus.extend(raw)\n",
    "\n",
    "print(\"데이터 크기:\", len(raw_corpus))\n",
    "print(\"Examples:\\n\", raw_corpus[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9d2442",
   "metadata": {},
   "source": [
    "## Step 3. 데이터 정제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3cc349",
   "metadata": {},
   "source": [
    "#### 앞서 배운 테크닉들을 활용해 문장 생성에 적합한 모양새로 데이터를 정제.\n",
    "\n",
    "(preprocess_sentence() 함수를 활용해 데이터를 정제.)\n",
    "1. 소문자로 바꾸고, 양쪽 공백을 지웁니다\n",
    "2. 특수문자 양쪽에 공백을 넣고\n",
    "3. 여러개의 공백은 하나의 공백으로 바꿉니다\n",
    "4. a-zA-Z?.!,¿가 아닌 모든 문자를 하나의 공백으로 바꿉니다\n",
    "5. 다시 양쪽 공백을 지웁니다\n",
    "6. 문장 시작에는 \\<start>, 끝에는 \\<end>를 추가합니다\n",
    "\n",
    "이 순서로 처리해주면 문제가 되는 상황을 방지할 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ee89a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> now i ve heard there was a secret chord <end>\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "\n",
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip() # 소문자 변경, 양쪽 공백 제거.\n",
    "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence) # 특수문자 양쪽 공백 처리.\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence) # 다수의 공백을 하나의 공백으로 처리.\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence) # 영어와 지정한 특수문자 제외 공백 처리.\n",
    "    sentence = sentence.strip() # 양쪽 공백 제거.\n",
    "    sentence = '<start> ' + sentence + ' <end>' # 문장 시작에는 <start>, 끝에는 <end>를 추가\n",
    "    return sentence\n",
    "\n",
    "print(preprocess_sentence(raw_corpus[0]))# 정제 결과 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4004057a",
   "metadata": {},
   "source": [
    "추가로 지나치게 긴 문장은 다른 데이터들이 과도한 Padding을 갖게 하므로 제거.\n",
    "(너무 긴 문장은 노래 가사 작사하기에 어울리지 않을 수도 있음.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfcc9e83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<start> now i ve heard there was a secret chord <end>',\n",
       " '<start> that david played , and it pleased the lord <end>',\n",
       " '<start> but you don t really care for music , do you ? <end>',\n",
       " '<start> it goes like this <end>',\n",
       " '<start> the fourth , the fifth <end>',\n",
       " '<start> the minor fall , the major lift <end>',\n",
       " '<start> the baffled king composing hallelujah hallelujah <end>']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = []\n",
    "\n",
    "for sentence in raw_corpus:\n",
    "    # 원하지 않는 문장은 건너뜀.\n",
    "    \n",
    "    if len(sentence) == 0 or len(sentence.split()) > 15: continue\n",
    "        # 길이가 0인 빈 문장 또는 토큰이 15개가 넘는 문장 건너뜀.\n",
    "        \n",
    "    if sentence[-1] == ']': continue\n",
    "        # ']'로 끝나는 파트를 나눈 문장 건너뜀.\n",
    "        \n",
    "    if sentence[-1] == ')': continue\n",
    "        # ')'로 끝나는 코러스 문장 건너뜀.\n",
    "        \n",
    "#    if sentence[-1] == \":\": continue # 가사가 ':'으로 마치는 경우 존재하므로 건너뛰지 않는다    \n",
    "    \n",
    "    # 정제를 하고 담아주세요\n",
    "    preprocessed_sentence = preprocess_sentence(sentence)\n",
    "    corpus.append(preprocessed_sentence)\n",
    "    \n",
    "# 정제된 결과 확인\n",
    "corpus[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08597c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus = []\n",
    "# for idx, sentence in enumerate(raw_corpus):\n",
    "#     # 아무것도 들어 있지 않은 문장 제외\n",
    "#     if len(sentence) == 0 : continue\n",
    "    \n",
    "#     preprocessed_sentence = preprocess_sentence(sentence)\n",
    "#     # 정제후 단어의 개수가 13개를 넘는 문장 제외\n",
    "#     if not ( preprocessed_sentence.count(' ')+1 <= 15) : continue\n",
    "#     # 정제후 단어의 개수가 1개인 문장 제외\n",
    "#     if preprocessed_sentence.count(' ')+1 <= 4 : continue\n",
    "#     # 정제하고 나니 corpus에 이미 등록되어 있는 경우는 건너뜀\n",
    "#     # if preprocessed_sentence in corpus : continue\n",
    "#     corpus.append(preprocessed_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bc4e34",
   "metadata": {},
   "source": [
    "#### 문장을 토큰화 했을 때 토큰의 개수가 15개를 넘어가는 문장을 학습 데이터에서 제외.\n",
    "토큰화 할 때 텐서플로우의 Tokenizer와 pad_sequences를 사용.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d621506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   2   49    5 ...    0    0    0]\n",
      " [   2   17 2618 ...    0    0    0]\n",
      " [   2   32    7 ...   45    3    0]\n",
      " ...\n",
      " [   2  258  192 ...   12    3    0]\n",
      " [   5   23    9 ...   10 1057    3]\n",
      " [   2    7   33 ...    0    0    0]] <keras_preprocessing.text.Tokenizer object at 0x7f7504562b20>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def tokenize(corpus):\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "        num_words=12000, \n",
    "        filters=' ',\n",
    "        oov_token=\"<unk>\"\n",
    "    )\n",
    "    # corpus를 이용해 tokenizer 내부의 단어장을 완성.\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    # 준비한 tokenizer를 이용해 corpus를 Tensor로 변환.\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)   \n",
    "    # 입력 데이터의 시퀀스 길이를 일정하게 맞춤.\n",
    "    # 만약 시퀀스가 짧다면 문장 뒤에 패딩을 붙여 길이를 맞춤.\n",
    "    # 문장 앞에 패딩을 붙여 길이를 맞추고 싶다면 padding='pre'를 사용.\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post', maxlen=15)  \n",
    "    \n",
    "    print(tensor,tokenizer)\n",
    "    return tensor, tokenizer\n",
    "\n",
    "tensor, tokenizer = tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "919edbeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : <unk>\n",
      "2 : <start>\n",
      "3 : <end>\n",
      "4 : ,\n",
      "5 : i\n",
      "6 : the\n",
      "7 : you\n",
      "8 : and\n",
      "9 : a\n",
      "10 : to\n"
     ]
    }
   ],
   "source": [
    "for idx in tokenizer.index_word:\n",
    "    print(idx, \":\", tokenizer.index_word[idx]) # 단어사전 내용 확인\n",
    "\n",
    "    if idx >= 10: break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5384fd07",
   "metadata": {},
   "source": [
    " ## Step 4. 평가 데이터셋 분리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e688f43",
   "metadata": {},
   "source": [
    "### 훈련 데이터와 평가 데이터를 분리.\n",
    "tokenize() 함수로 데이터를 Tensor로 변환한 후, sklearn 모듈의 train_test_split() 함수를 사용해 훈련 데이터와 평가 데이터를 분리.\n",
    "#### 단어장의 크기는 12,000 이상 으로 설정.\n",
    "#### 총 데이터의 20% 를 평가 데이터셋으로 사용."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f7fa55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Train: (127837, 14)\n",
      "Target Train: (127837, 14)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "src_input = tensor[:, :-1]  \n",
    "tgt_input = tensor[:, 1:]    \n",
    "\n",
    "enc_train, enc_val, dec_train, dec_val = train_test_split(src_input, tgt_input, test_size = 0.2)\n",
    "enc_val_train, enc_val_val, dec_val_train, dec_val_val = train_test_split(enc_train, dec_train, test_size = 0.2) \n",
    "print(\"Source Train:\", enc_train.shape)\n",
    "print(\"Target Train:\", dec_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd7249c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((256, 14), (256, 14)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BUFFER_SIZE = len(src_input)\n",
    "BATCH_SIZE = 256\n",
    "steps_per_epoch = len(src_input) // BATCH_SIZE\n",
    "\n",
    " # tokenizer가 구축한 단어사전 내 12,000개와, 여기 포함되지 않은 0:<pad>를 포함하여 12,001개\n",
    "VOCAB_SIZE = tokenizer.num_words + 1   \n",
    "\n",
    "# 준비한 데이터 소스로부터 데이터셋을 만듬.\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((src_input, tgt_input))\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af157cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Train: (127837, 14)\n",
      "Target Train: (127837, 14)\n"
     ]
    }
   ],
   "source": [
    "print(\"Source Train:\", enc_train.shape)\n",
    "print(\"Target Train:\", dec_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614eb850",
   "metadata": {},
   "source": [
    "## Step 5. 인공지능 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e83b28",
   "metadata": {},
   "source": [
    "모델의 Embedding Size와 Hidden Size를 조절하며 10 Epoch 안에 val_loss 값을 2.2 수준으로 줄일 수 있는 모델을 설계. (Loss는 아래 제시된 Loss 함수를 그대로 사용.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f81c686",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerator(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
    "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.rnn_1(out)\n",
    "        out = self.rnn_2(out)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    \n",
    "embedding_size = 256\n",
    "hidden_size = 1024\n",
    "lyricist = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48a986f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(256, 14, 12001), dtype=float32, numpy=\n",
       "array([[[-1.44154052e-04, -6.53484822e-05, -1.58454743e-04, ...,\n",
       "          1.09955217e-04, -7.10229233e-06, -8.26604737e-05],\n",
       "        [-1.50740190e-04, -3.41225059e-05, -2.73217360e-04, ...,\n",
       "          3.56156146e-04,  1.07076645e-04, -1.49429587e-04],\n",
       "        [-2.75510276e-04, -1.41341123e-04, -3.72998882e-04, ...,\n",
       "          7.20555137e-04,  3.91176181e-05, -3.21971806e-04],\n",
       "        ...,\n",
       "        [-1.19180628e-03, -8.89089715e-04, -3.93882510e-04, ...,\n",
       "          9.87562016e-05,  1.03227410e-03, -1.78727636e-03],\n",
       "        [-1.03560125e-03, -1.08568359e-03, -7.95994943e-04, ...,\n",
       "          3.91249050e-05,  1.03292195e-03, -1.70092320e-03],\n",
       "        [-8.70454474e-04, -1.23841001e-03, -1.16272550e-03, ...,\n",
       "         -1.09324164e-05,  1.02774799e-03, -1.51110464e-03]],\n",
       "\n",
       "       [[-1.44154052e-04, -6.53484822e-05, -1.58454743e-04, ...,\n",
       "          1.09955217e-04, -7.10229233e-06, -8.26604737e-05],\n",
       "        [-2.90683674e-04,  2.30848047e-04, -3.54613003e-04, ...,\n",
       "          2.58024607e-04,  1.14391216e-04,  1.21915553e-04],\n",
       "        [-3.42056155e-04,  6.96109317e-04, -5.48914213e-05, ...,\n",
       "          6.02773391e-04,  8.89100629e-05,  1.50011547e-04],\n",
       "        ...,\n",
       "        [ 6.19663158e-04, -8.07608187e-04, -2.80195288e-03, ...,\n",
       "          4.22393117e-04,  2.89462885e-04,  1.43443129e-03],\n",
       "        [ 8.29404802e-04, -1.08726393e-03, -3.13722366e-03, ...,\n",
       "          3.09968716e-04,  2.23540395e-04,  1.77401444e-03],\n",
       "        [ 1.03273441e-03, -1.34867616e-03, -3.45536182e-03, ...,\n",
       "          1.90976411e-04,  1.52131615e-04,  2.09845137e-03]],\n",
       "\n",
       "       [[-1.44154052e-04, -6.53484822e-05, -1.58454743e-04, ...,\n",
       "          1.09955217e-04, -7.10229233e-06, -8.26604737e-05],\n",
       "        [-4.15982300e-04, -2.56199564e-04, -2.79077241e-04, ...,\n",
       "          1.94534568e-05,  1.33930676e-04, -1.37083509e-04],\n",
       "        [-3.71479924e-04, -5.07488032e-04, -4.55149100e-04, ...,\n",
       "          1.32860077e-04,  7.00574747e-05,  8.60914679e-06],\n",
       "        ...,\n",
       "        [-4.00221033e-04, -1.34081813e-03, -3.19359498e-03, ...,\n",
       "          6.07345311e-04,  5.97746111e-04,  1.01581577e-03],\n",
       "        [-1.68053128e-04, -1.42742135e-03, -3.42170382e-03, ...,\n",
       "          5.38361084e-04,  5.65653318e-04,  1.33945944e-03],\n",
       "        [ 8.13099468e-05, -1.53489015e-03, -3.64349713e-03, ...,\n",
       "          4.43824159e-04,  5.08350262e-04,  1.67483289e-03]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-1.44154052e-04, -6.53484822e-05, -1.58454743e-04, ...,\n",
       "          1.09955217e-04, -7.10229233e-06, -8.26604737e-05],\n",
       "        [-3.82069265e-04,  6.14782766e-05, -1.89810424e-04, ...,\n",
       "          1.77386930e-04,  9.73430215e-05, -1.55978705e-04],\n",
       "        [-4.07675834e-04,  6.38049387e-05, -3.66639695e-04, ...,\n",
       "          1.13807560e-04,  1.65363948e-04,  5.63154754e-05],\n",
       "        ...,\n",
       "        [ 8.33340091e-05, -7.41436437e-04, -2.20142049e-03, ...,\n",
       "         -5.30025398e-04,  1.27336214e-04,  8.36576655e-05],\n",
       "        [ 2.55668798e-04, -9.31567396e-04, -2.47113989e-03, ...,\n",
       "         -4.83794953e-04,  1.63536271e-04,  4.05755389e-04],\n",
       "        [ 4.49055922e-04, -1.11953332e-03, -2.74083368e-03, ...,\n",
       "         -4.55742702e-04,  1.75079913e-04,  7.60293857e-04]],\n",
       "\n",
       "       [[-1.44154052e-04, -6.53484822e-05, -1.58454743e-04, ...,\n",
       "          1.09955217e-04, -7.10229233e-06, -8.26604737e-05],\n",
       "        [-2.63317197e-04, -1.01431942e-04, -1.63168515e-04, ...,\n",
       "          1.06748121e-04, -1.92188454e-04, -9.61643382e-05],\n",
       "        [-1.36967559e-04,  1.92806430e-04, -1.79700321e-04, ...,\n",
       "          2.70242163e-04, -1.87073922e-04,  3.84197192e-05],\n",
       "        ...,\n",
       "        [-4.47144266e-04, -1.18618435e-03, -2.26979982e-03, ...,\n",
       "         -2.11435094e-04,  1.36908435e-04,  1.12382557e-04],\n",
       "        [-2.29360536e-04, -1.40353071e-03, -2.61089369e-03, ...,\n",
       "         -1.92628228e-04,  1.84934266e-04,  3.79853882e-04],\n",
       "        [ 1.85622575e-05, -1.59792276e-03, -2.93539371e-03, ...,\n",
       "         -1.93402680e-04,  2.03102696e-04,  6.97165669e-04]],\n",
       "\n",
       "       [[-1.44154052e-04, -6.53484822e-05, -1.58454743e-04, ...,\n",
       "          1.09955217e-04, -7.10229233e-06, -8.26604737e-05],\n",
       "        [-3.33591801e-04, -1.94614709e-04, -2.39907633e-04, ...,\n",
       "          8.03473376e-05,  3.33007541e-04, -4.09252738e-04],\n",
       "        [-4.49556683e-04, -8.96533747e-05, -4.37644543e-04, ...,\n",
       "          2.28819248e-04,  4.03263693e-04, -5.75001875e-04],\n",
       "        ...,\n",
       "        [-1.32961417e-04, -1.43248693e-03, -2.53408472e-03, ...,\n",
       "          1.18641986e-03,  5.64583461e-04,  6.50009781e-04],\n",
       "        [ 5.07613695e-05, -1.58252195e-03, -2.79105082e-03, ...,\n",
       "          1.02306972e-03,  5.10075828e-04,  1.00309378e-03],\n",
       "        [ 2.55390769e-04, -1.72599568e-03, -3.05474200e-03, ...,\n",
       "          8.35315906e-04,  4.37956187e-04,  1.36449328e-03]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for src_sample, tgt_sample in dataset.take(1): break\n",
    "\n",
    "# 한 배치만 불러온 데이터를 모델에 넣어봄.\n",
    "lyricist(src_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f13c4f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"text_generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        multiple                  3072256   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  multiple                  5246976   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                multiple                  8392704   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  12301025  \n",
      "=================================================================\n",
      "Total params: 29,012,961\n",
      "Trainable params: 29,012,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lyricist.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46b1b326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "624/624 [==============================] - 98s 153ms/step - loss: 3.6408\n",
      "Epoch 2/10\n",
      "624/624 [==============================] - 101s 161ms/step - loss: 3.1224\n",
      "Epoch 3/10\n",
      "624/624 [==============================] - 103s 164ms/step - loss: 2.9354\n",
      "Epoch 4/10\n",
      "624/624 [==============================] - 104s 166ms/step - loss: 2.7850\n",
      "Epoch 5/10\n",
      "624/624 [==============================] - 104s 166ms/step - loss: 2.6545\n",
      "Epoch 6/10\n",
      "624/624 [==============================] - 104s 167ms/step - loss: 2.5323\n",
      "Epoch 7/10\n",
      "624/624 [==============================] - 104s 166ms/step - loss: 2.4165\n",
      "Epoch 8/10\n",
      "624/624 [==============================] - 104s 166ms/step - loss: 2.3073\n",
      "Epoch 9/10\n",
      "624/624 [==============================] - 104s 166ms/step - loss: 2.2045\n",
      "Epoch 10/10\n",
      "624/624 [==============================] - 104s 167ms/step - loss: 2.1064\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f745c2443d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "# optimizer = tf.keras.optimizers.SGD()\n",
    "\n",
    "#Loss\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "lyricist.compile(loss=loss, optimizer=optimizer)\n",
    "lyricist.fit(dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc5de0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(lyricist, tokenizer, init_sentence=\"<start>\", max_len=20):\n",
    "    # 테스트를 위해서 입력받은 init_sentence도 텐서로 변환합니다\n",
    "    test_input = tokenizer.texts_to_sequences([init_sentence])\n",
    "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
    "    end_token = tokenizer.word_index[\"<end>\"]\n",
    "\n",
    "    # 단어 하나씩 예측해 문장을 만듭니다\n",
    "    #    1. 입력받은 문장의 텐서를 입력합니다\n",
    "    #    2. 예측된 값 중 가장 높은 확률인 word index를 뽑아냅니다\n",
    "    #    3. 2에서 예측된 word index를 문장 뒤에 붙입니다\n",
    "    #    4. 모델이 <end>를 예측했거나, max_len에 도달했다면 문장 생성을 마칩니다\n",
    "    while True:\n",
    "        # 1\n",
    "        predict = lyricist(test_tensor) \n",
    "        # 2\n",
    "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1] \n",
    "        # 3 \n",
    "        test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
    "        # 4\n",
    "        if predict_word.numpy()[0] == end_token: break\n",
    "        if test_tensor.shape[1] >= max_len: break\n",
    "\n",
    "    generated = \"\"\n",
    "    # tokenizer를 이용해 word index를 단어로 하나씩 변환합니다 \n",
    "    for word_index in test_tensor[0].numpy():\n",
    "        generated += tokenizer.index_word[word_index] + \" \"\n",
    "\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651bbfa8",
   "metadata": {},
   "source": [
    "모델이 생성한 가사 한 줄을 제출."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f35adce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> i love you , i m better <end> '"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(lyricist, tokenizer, init_sentence=\"<start> i love\", max_len=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0d0f47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
