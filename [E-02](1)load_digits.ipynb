{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3177f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1)필요한 모듈 import하기\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score # 모델 평가에 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f187c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DESCR', 'data', 'feature_names', 'frame', 'images', 'target', 'target_names']\n"
     ]
    }
   ],
   "source": [
    "# (2) 데이터 준비\n",
    "# load_digits 메서드를 사용\n",
    "\n",
    "digits = load_digits()\n",
    "print(dir(digits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d8a7096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (3)데이터 이해하기\n",
    "\n",
    "# (3)-1. Feature Data 지정\n",
    "\n",
    "digits_data = digits.data\n",
    "digits_data.shape    ## shape는 배열의 형상정보를 출력(데이터 형태)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24021c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "    ## digits_data에 저장된 데이터 양과 형식 확인\n",
    "    ## 1797개의 digit 데이터와 각각의 데이터에 64개의 픽셀값이 저장되어 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a510ead5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, ..., 8, 9, 8])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (3)-2. Label Data 지정\n",
    "\n",
    "digits_label = digits.target\n",
    "print(digits_label.shape)\n",
    "digits_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dbbe39a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (3)-3. Target Names 출력\n",
    "\n",
    "digits.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6aa1157",
   "metadata": {},
   "outputs": [],
   "source": [
    "    ## Target_Name는 0~9까지의 숫자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f72ab220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _digits_dataset:\n",
      "\n",
      "Optical recognition of handwritten digits dataset\n",
      "--------------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 1797\n",
      "    :Number of Attributes: 64\n",
      "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
      "    :Date: July; 1998\n",
      "\n",
      "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "\n",
      "The data set contains images of hand-written digits: 10 classes where\n",
      "each class refers to a digit.\n",
      "\n",
      "Preprocessing programs made available by NIST were used to extract\n",
      "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
      "total of 43 people, 30 contributed to the training set and different 13\n",
      "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
      "4x4 and the number of on pixels are counted in each block. This generates\n",
      "an input matrix of 8x8 where each element is an integer in the range\n",
      "0..16. This reduces dimensionality and gives invariance to small\n",
      "distortions.\n",
      "\n",
      "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
      "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
      "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
      "1994.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
      "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
      "    Graduate Studies in Science and Engineering, Bogazici University.\n",
      "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
      "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
      "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
      "    Electrical and Electronic Engineering Nanyang Technological University.\n",
      "    2005.\n",
      "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
      "    Algorithm. NIPS. 2000.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (3)-4. 데이터 Describe 해 보기\n",
    "\n",
    "print(digits.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4abddf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train 개수:  1437 , X_test 개수:  360\n"
     ]
    }
   ],
   "source": [
    "# (4) train, test 데이터 분리\n",
    "\n",
    "# 모델 학습과 테스트용 문제지와 정답지를 준비\n",
    "# X_train, X_test, y_train, y_test를 생성하는 방법을 참고\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits_data, \n",
    "                                                    digits_label, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=7)\n",
    "\n",
    "print('X_train 개수: ', len(X_train),', X_test 개수: ', len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f691f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "    ## digits 데이터 셋을 학습용 데이터와 테스트용 데이터로 분리\n",
    "    ## test 데이터 셋의 크기는 전체 데이터셋의 20%\n",
    "    ## 1797개의 데이터셋 - 학습용 데이터: 1437개, 테스트용 데이터: 360개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b5f81b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        43\n",
      "           1       0.81      0.81      0.81        42\n",
      "           2       0.79      0.82      0.80        40\n",
      "           3       0.79      0.91      0.85        34\n",
      "           4       0.83      0.95      0.89        37\n",
      "           5       0.90      0.96      0.93        28\n",
      "           6       0.84      0.93      0.88        28\n",
      "           7       0.96      0.82      0.89        33\n",
      "           8       0.88      0.65      0.75        43\n",
      "           9       0.78      0.78      0.78        32\n",
      "\n",
      "    accuracy                           0.86       360\n",
      "   macro avg       0.86      0.86      0.86       360\n",
      "weighted avg       0.86      0.86      0.85       360\n",
      "\n",
      "0.8555555555555555\n"
     ]
    }
   ],
   "source": [
    "# (5) 다양한 모델로 학습시켜보기\n",
    "# 학습데이터 X_train, y_train 을 활용해 분류기 모델을 만들어 보자.\n",
    "\n",
    "\n",
    "# (5)-1. Decision Tree 사용해 보기\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier # 모델을 import해서 가져오기\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(random_state=32)\n",
    "decision_tree.fit(X_train, y_train) # decision_tree 라는 변수에 모델을 저장\n",
    "y_pred = decision_tree.predict(X_test) # Decision Tree 모델, 학습 - 결과\n",
    "\n",
    "\n",
    "digit_acc={}   # 손글씨 데이터의 정확도 dictionary\n",
    "digit_acc['Decision Tree'] = accuracy_score(y_test, y_pred) # Decision Tree 모델 평가\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(digit_acc['Decision Tree'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f230fab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree, accuracy : 86%    \n",
    "    \n",
    "    \n",
    "    ## Precision\n",
    "        ## 0, 5, 7, 8 을 제외한 나머지에서 평균 precision(macro avg)보다 낮음.\n",
    "        ## 0, 5, 7, 8 의 경우, 다른 숫자들에 비해서 정밀한 예측.\n",
    "\n",
    "    ## Recall\n",
    "        ## 0, 3, 4, 5, 6 을 제외한 나머지에서 평균 recall(macro avg)보다 낮음.\n",
    "        ## 0, 3, 4, 5, 6 의 경우, 해당 숫자 내에서 정확한 예측.\n",
    "\n",
    "        \n",
    "    ## 각각의 label에 따라서 precision과 recall의 편차가 큰 편이기에, 모델의 성능이 좋다고 말할 수 없음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5158ab07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        43\n",
      "           1       0.93      1.00      0.97        42\n",
      "           2       1.00      1.00      1.00        40\n",
      "           3       1.00      1.00      1.00        34\n",
      "           4       0.93      1.00      0.96        37\n",
      "           5       0.90      0.96      0.93        28\n",
      "           6       1.00      0.96      0.98        28\n",
      "           7       0.94      0.97      0.96        33\n",
      "           8       1.00      0.84      0.91        43\n",
      "           9       0.94      0.94      0.94        32\n",
      "\n",
      "    accuracy                           0.96       360\n",
      "   macro avg       0.96      0.96      0.96       360\n",
      "weighted avg       0.97      0.96      0.96       360\n",
      "\n",
      "0.9638888888888889\n"
     ]
    }
   ],
   "source": [
    "# (5)-2. Random Forest 사용해 보기\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest = RandomForestClassifier(random_state=32)\n",
    "random_forest.fit(X_train, y_train)\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "digit_acc['Random Forest'] = accuracy_score(y_test, y_pred) ## Random Forest 모델 평가\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(digit_acc['Random Forest'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fcbe17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest, accuracy : 96%\n",
    "\n",
    "\n",
    "    ## Precision\n",
    "        ## 0, 2, 3, 6, 8 을 제외한 나머지에서 평균 precision(macro avg)보다 낮음.\n",
    "        ## 0, 2, 3, 6, 8 의 경우, 다른 숫자들에 비해서 정밀한 예측.\n",
    "        \n",
    "    ## Recall\n",
    "        ## 1, 2, 3, 4, 5, 6, 7 을 제외한 나머지에서 평균 recall(macro avg)보다 낮음.\n",
    "        ## 1, 2, 3, 4, 5, 6, 7 의 경우, 해당 숫자 내에서 정확한 예측.\n",
    "        ### 특히, 8의 경우, recall값 : 0.84 - 실제 8 데이터 중에서 8이라고 예측한 결과가 굉장히 적음.\n",
    "\n",
    "        \n",
    "    ## precision과 recall의 각 label 별 편차가 대체적으로 크지 않고,\n",
    "    ## 전반적으로 0.9 이상의 값을 갖기때문에, 모델의 성능이 좋다고 말할 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e069da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n"
     ]
    }
   ],
   "source": [
    "# (5)-3. # SVM 사용해 보기\n",
    "\n",
    "from sklearn import svm\n",
    "svm_model = svm.SVC()\n",
    "\n",
    "print(svm_model._estimator_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb3401b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.95      1.00      0.98        42\n",
      "           2       1.00      1.00      1.00        40\n",
      "           3       1.00      1.00      1.00        34\n",
      "           4       1.00      1.00      1.00        37\n",
      "           5       0.93      1.00      0.97        28\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        33\n",
      "           8       1.00      0.93      0.96        43\n",
      "           9       1.00      0.97      0.98        32\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n",
      "0.9888888888888889\n"
     ]
    }
   ],
   "source": [
    "# SVM 모델 학습 - 결과\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "digit_acc['SVM'] = accuracy_score(y_test, y_pred) ## SVM 모델 평가\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(digit_acc['SVM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e159736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM, accuracy : 99%\n",
    "\n",
    "    ## 99%라는 너무 높은 accuracy를 갖기 때문에, 믿을 수 있는 수치인지 의문.\n",
    "    \n",
    "    \n",
    "    ## Precision\n",
    "        ## 1, 5 에서 평균 precision(macro avg)보다 낮음.\n",
    "        ## 대부분 정밀한 예측.\n",
    "        \n",
    "    ## Recall\n",
    "        ## 8, 9 에서 평균 recall(macro avg)보다 낮음.\n",
    "        ## 대부분 해당 숫자 내에서 정확한 예측.\n",
    "        \n",
    "        \n",
    "    ## precision과 recall의 각 label 별 편차가 대체적으로 크지 않고,\n",
    "    ## 전반적으로 0.9 이상의 값을 갖음.\n",
    "        ## but, 99%의 정확도는 굉장히 높은 수치이며, 해당 모델의 성능에 대한 의심.\n",
    "        ## if, 해당 모델의 성능이 사실이라면, 해당 프로젝트에서는 SVM 모델을 사용하는 것이 가장 좋음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2bcafed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n"
     ]
    }
   ],
   "source": [
    "# (5)-4. # SGD Classifier 사용해 보기\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_model = SGDClassifier()\n",
    "\n",
    "print(sgd_model._estimator_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "59fd7053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        43\n",
      "           1       0.94      0.81      0.87        42\n",
      "           2       0.98      1.00      0.99        40\n",
      "           3       0.94      0.91      0.93        34\n",
      "           4       0.95      1.00      0.97        37\n",
      "           5       0.93      0.96      0.95        28\n",
      "           6       1.00      0.93      0.96        28\n",
      "           7       0.97      0.97      0.97        33\n",
      "           8       0.74      0.91      0.81        43\n",
      "           9       0.96      0.84      0.90        32\n",
      "\n",
      "    accuracy                           0.93       360\n",
      "   macro avg       0.94      0.93      0.93       360\n",
      "weighted avg       0.94      0.93      0.93       360\n",
      "\n",
      "0.9305555555555556\n"
     ]
    }
   ],
   "source": [
    "# SGD 모델 학습 - 결과\n",
    "sgd_model.fit(X_train, y_train)\n",
    "y_pred = sgd_model.predict(X_test)\n",
    "\n",
    "digit_acc['SGD Classifier'] = accuracy_score(y_test, y_pred) ## SGD 모델 평가\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(digit_acc['SGD Classifier'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b339ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD, accuracy : 95%\n",
    " \n",
    "    \n",
    "    ## Precision\n",
    "        ## 3, 5, 8, 9 를 제외한 나머지에서 평균 precision(macro avg)보다 높음.\n",
    "        ## 3, 5, 8, 9 의 경우, 다른 숫자들에 비해서 정밀도가 떨어짐.\n",
    "        \n",
    "    ## Recall\n",
    "        ## 1, 8, 9 을 제외한 나머지에서 평균 recall(macro avg)보다 높음.\n",
    "        ## 1, 8, 9 의 경우, 해당 숫자 내에서 정확한 예측을 한 비율이 적음.\n",
    "        ### 특히, 1의 경우, recall값 : 0.83 - 실제 1 데이터 중에서 1이라고 예측한 결과가 굉장히 적음.\n",
    "        \n",
    "        \n",
    "    ## but, 일부 label에서 precision과 recall 값이 다른 label에 비해서 많이 낮음.\n",
    "        \n",
    "        ## 이유? SGD의 특성으로 인한 결과!\n",
    "        ## SGD는 추출된 데이터 한개에 대해서 그래디언트를 계산하고, 경사 하강 알고리즘을 적용하는 방식.\n",
    "        ## 전체 데이터를 사용하는 것이 아니라, 랜덤하게 추출한 일부 데이터를 사용.\n",
    "        ## 속도가 매우 빠르지만, 학습 중간 과정에서 결과의 진폭이 크고 불안정.\n",
    "        ## 데이터를 하나씩 처리하기 때문에 오차율이 크고, GPU의 성능을 모두 활용하지 못함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a66ffa48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n"
     ]
    }
   ],
   "source": [
    "# (5)-5. # Logistic Regression 사용해 보기\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic_model = LogisticRegression()\n",
    "\n",
    "print(logistic_model._estimator_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75b57e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.95      0.95      0.95        42\n",
      "           2       0.98      1.00      0.99        40\n",
      "           3       0.94      0.97      0.96        34\n",
      "           4       0.97      1.00      0.99        37\n",
      "           5       0.82      0.96      0.89        28\n",
      "           6       1.00      0.96      0.98        28\n",
      "           7       0.97      0.97      0.97        33\n",
      "           8       0.92      0.81      0.86        43\n",
      "           9       0.97      0.91      0.94        32\n",
      "\n",
      "    accuracy                           0.95       360\n",
      "   macro avg       0.95      0.95      0.95       360\n",
      "weighted avg       0.95      0.95      0.95       360\n",
      "\n",
      "0.9527777777777777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression 모델 학습 - 결과\n",
    "logistic_model.fit(X_train, y_train)\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "\n",
    "digit_acc['Logistic Regression'] = accuracy_score(y_test, y_pred) ## Logistic Regression 모델 평가\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(digit_acc['Logistic Regression'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "623eab16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression, accuracy : 95%\n",
    "\n",
    "\n",
    "    ## precision\n",
    "        ## 5, 8 를 제외한 나머지에서 평균 precision(macro avg)보다 높음.\n",
    "        ## 5, 8 의 경우, 다른 숫자들에 비해서 정밀도가 떨어짐.\n",
    "        \n",
    "    ## Recall\n",
    "        ## 8, 9을 제외한 나머지에서 평균 recall(macro avg)보다 높음.\n",
    "        ## 8, 9의 경우, 해당 숫자 내에서 정확한 예측을 한 비율이 적음.\n",
    "        \n",
    "        \n",
    "        ## 오류\n",
    "            ## 학습에 따른 모델의 convergence가 이루어지지 않았기에 발생함.\n",
    "            ## 학습에 대한 모델의 최적화가 이루어지지 않음.\n",
    "        \n",
    "        ## 해결방법?\n",
    "            ## 학습 데이터의 양이 증가하면, 해당 오류를 해결할 수 있지 않을까 생각함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "53db3261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (6) 모델을 평가해 보기\n",
    "# 학습된 모델들의 테스트데이터 예측 결과를 어떻게 해석해야 할까요?\n",
    "# 모델의 성능을 평가하는 지표로는 무엇이 좋을까요?\n",
    "# sklearn.metrics 에서 제공하는 평가지표 중 적절한 것을 선택해 보세요.\n",
    "# 선택하신 이유도 설명해 주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b47d0179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree, accuracy : 86%\n",
    "# Random Forest, accuracy : 96%\n",
    "# SVM, accuracy : 99%\n",
    "# SGD, accuracy : 95%\n",
    "# Logistic Regression, accuracy : 95%\n",
    "\n",
    "\n",
    "# Decision Tree, accuracy : 86%\n",
    "    ## 각각의 label에 따라서 precision과 recall의 편차가 큰 편이기에, 모델의 성능이 좋다고 말할 수 없음.\n",
    "\n",
    "\n",
    "# Random Forest, accuracy : 96%\n",
    "    ## precision과 recall의 각 label 별 편차가 대체적으로 크지 않고,\n",
    "    ## 전반적으로 0.9 이상의 값을 갖기때문에, 모델의 성능이 좋다고 말할 수 있음.\n",
    "\n",
    "\n",
    "# SVM, accuracy : 99%\n",
    "    ## precision과 recall의 각 label 별 편차가 대체적으로 크지 않고,\n",
    "    ## 전반적으로 0.9 이상의 값을 갖음.\n",
    "        ## but, 99%의 정확도는 굉장히 높은 수치이며, 해당 모델의 성능에 대한 의심.\n",
    "        ## if, 해당 모델의 성능이 사실이라면, 해당 프로젝트에서는 SVM 모델을 사용하는 것이 가장 좋음.\n",
    "\n",
    "\n",
    "# SGD, accuracy : 95%\n",
    "    ## 일부 label에서 precision과 recall 값이 다른 label에 비해서 많이 낮음.\n",
    "        \n",
    "        ## 이유? SGD의 특성으로 인한 결과!\n",
    "        ## SGD는 추출된 데이터 한개에 대해서 그래디언트를 계산하고, 경사 하강 알고리즘을 적용하는 방식.\n",
    "        ## 전체 데이터를 사용하는 것이 아니라, 랜덤하게 추출한 일부 데이터를 사용.\n",
    "        ## 속도가 매우 빠르지만, 학습 중간 과정에서 결과의 진폭이 크고 불안정.\n",
    "        ## 데이터를 하나씩 처리하기 때문에 오차율이 크고, GPU의 성능을 모두 활용하지 못함.\n",
    "\n",
    "\n",
    "# Logistic Regression, accuracy : 95%\n",
    "        ## 오류\n",
    "            ## 학습에 따른 모델의 convergence가 이루어지지 않았기에 발생함.\n",
    "            ## 학습에 대한 모델의 최적화가 이루어지지 않음.\n",
    "        \n",
    "        ## 해결방법?\n",
    "            ## 학습 데이터의 양이 증가하면, 해당 오류를 해결할 수 있지 않을까 생각함.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "edb5f71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree        : 0.8555555555555555\n",
      "Random Forest        : 0.9638888888888889\n",
      "SVM                  : 0.9888888888888889\n",
      "SGD Classifier       : 0.9305555555555556\n",
      "Logistic Regression  : 0.9527777777777777\n"
     ]
    }
   ],
   "source": [
    "# sklearn.metrics 에서 제공하는 평가지표\n",
    "\n",
    "    ## 사이킷런 패키지에서 지원하는 분류 성능평가 명령\n",
    "    ## 사이킷런 패키지는 metrics 서브패키지에서 다음처럼 다양한 분류용 성능평가 명령을 제공.\n",
    "\n",
    "        # confusion_matrix(y_true, y_pred)\n",
    "        # accuracy_score(y_true, y_pred) *\n",
    "        # precision_score(y_true, y_pred)\n",
    "        # recall_score(y_true, y_pred)\n",
    "        # fbeta_score(y_true, y_pred, beta)\n",
    "        # f1_score(y_true, y_pred)\n",
    "        # classfication_report(y_true, y_pred) *\n",
    "        # roc_curve\n",
    "        # auc\n",
    "\n",
    "## digits datasets의 경우 사실 Recall과 Precision등의 영향을 받지 않는 데이터임.\n",
    "## digit의 경우 정답 또는 오류를 틀리게 예측한 것을 파악하는 것보다 오류를 바르게 예측하는게 더 중요함.\n",
    "## 단순히 정확도만 확인해도 무방하기 때문에 Accuracy를 평가지료로 사용하면 될 것 같음.\n",
    "    ## classfication_report(y_true, y_pred)를 사용하여 결과값과 정확성을 알 수 있지만\n",
    "    ## 한눈에 보기 쉽게 각 모델들의 ccuracy값을 accuracy_score(y_true, y_pred)로 정리.\n",
    "    \n",
    "for i in digit_acc.items():\n",
    "    print(\"{0:<20} : {1}\".format(i[0],i[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a54e7722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 회고\n",
    "\n",
    "# 정리하자면, 정확도가 가장 높은 수치를 보인 모델은 98%로 SVM이다.\n",
    "# 해당 프로젝트의 경우, SVM 모델의 성능이 가장 좋다고 생각한다.\n",
    "\n",
    "# digit의 경우 정답 또는 오류를 틀리게 예측한 것을 파악하는 것보다\n",
    "# 오류를 바르게 예측하는게 더 중요하다고 생각했다.\n",
    "# 따라서, 단순히 정확도만 확인해도 무방하기 때문에 Accuracy를 평가지료로 사용했다.\n",
    "\n",
    "# (마지막에 각 모델들의 성능을 한눈에 보기 위해 dictionary의 .items() 함수를 사용했다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08a8e68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
